# AIminer AI Server Configuration
# Copy this file to .env and edit the values

# Path to GGUF model file
# Supported models: Mistral-7B, Llama-2, Llama-3, etc.
# NOT supported: MXFP4 format, Vision-Language models, Qwen3 architecture
AIMINER_MODEL_PATH=models/Mistral-7B-Instruct-v0.3-Q4_K_M.gguf

# Server port
AIMINER_PORT=8080
